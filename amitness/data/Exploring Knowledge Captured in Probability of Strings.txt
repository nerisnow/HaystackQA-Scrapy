I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.I recently completed the UC Berkeley’s  course. The course had an interesting  on the history of language modeling by Alec Radford, the author of GPT model.In one of his slides, Alec mentions how by simply observing a bunch of strings, language models tend to capture useful knowledge. He also mentions that maybe in the future, we could have an unsupervised language model that can be directly used on tasks without further fine-tuning. This talk was before GPT-3 was released and GPT-3 has shown the few-shot learning ability of language models.In this post, I will share my exploration of the simple examples he mentioned in the lecture with code and expand more on them.In language modeling, we want to learn a function that can observe a bunch of strings and then compute the probability for new strings. For example, the function can give us how likely this sentence is:There are many ways you could formulate this function. Here are some:We could use an RNN and variants to keep track of the previous context in a hidden state.Let’s take GPT-2 as a language model and explore what it has learned by just observing a bunch of strings over the internet.We will use the  library to calculate the probability of a sentence using transformer-based language models.Let’s create a scorer function that gives us a probability of a sentence using the GPT-2 language model.Now, we can use it for any sentence as shown below and it returns the probability.A language model has no prior knowledge of grammar rules and structure. But it has been exposed to a bunch of grammatically correct sentences in the large training corpus. Let’s explore how much grammar it has picked up.The language model assigns a higher probability to sentence with the correct order of subject, verb, and object than an incorrect one.We have two similar sentences given below. Sentence 2 has a grammatical mistake.We would want our language model to assign more probability to the correct sentence 1. Let’s verify if this is the case with GPT-2.The language model indeed assigns more probability to the gramatically correct sentence.The text corpus a language model is trained on contains lots of facts about the world. Can a language model pick that up? Let’s see an example.Who does GPT-2 think is more probable to sit on a mat: cat or the hyena?It’s the cat. This makes sense as cats are domesticated and hyena is a wild animal.Alec presents another idea where we find the conditional probability of positive/negative opinion following some text to perform sentiment analysis. For example, we could calculate the probability for “Sentiment: Positive.” and “Sentiment: Negative.” coming after a text and assign the sentiment as positive or negative respectively.Let’s build a function to compute the two scores and return the sentiment based on whichever is higher.We can try with a few sentences.Since these models are trained on human-written text in the wild, they are bound to capture the inherent bias in these text. Here are some examples:The model finding it more probable for gender to be “he” for doctor and scientist and “she” for nurse.