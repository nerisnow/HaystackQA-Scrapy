The recent release of GPT-3 got me interested in the state of zero-shot learning and few-shot learning in NLP. While most of the zero-shot learning research is concentrated in Computer Vision, there has been some interesting work in the NLP domain as well.I will be writing a series of blog posts to cover existing research on zero-shot learning in NLP. In this first post, I will explain the paper  by Pushp et al. This paper from December 2017 was the first work to propose a zero-shot learning paradigm for text classification.Zero-Shot Learning is the ability to detect classes that the model has never seen during training. It resembles our ability as humans to generalize and identify new things without explicit supervision.For example, let’s say we want to do  and  classification. Normally, we will train/fine-tune a new model for each dataset. In contrast, with zero-shot learning, you can perform tasks such as sentiment and news classification directly without any task-specific training.
In the paper, the authors propose a simple idea for zero-shot classification. Instead of classifying texts into X classes, they re-formulate the task as a binary classification to determine if a text and a class are related or not. 
Let’s understand their formulation and end-to-end process in more detail now.The authors crawled 4.2 million  from the web and used the  for the news article as the . After crawling, they got total  as the labels. We can see how troublesome it would have been if we had to train a supervised model on .

Each  was truncated to 28 words and anything shorter was padded.The paper uses word2vec pre-trained on Google News as the word embeddings for both the sentences as well as the labels.The paper proposes three different architecture to learn the relation between sentence and label embeddings.In this architecture, we take the mean of word embeddings in the sentence as the sentence embedding and concatenate it with the . This vector is then passed through a  to classify if the sentence and label are related or not.In this architecture, instead of taking the mean, the word embeddings are passed through an LSTM and the  of the network is treated as the sentence vector. It is concatenated with the  and then passed through a  to classify if the sentence and label are related or not.In this architecture, the embedding of each word in the sentence is concatenated with the . This combined embedding is passed through an LSTM and the  of the network is taken. It is then passed through a  to classify if the sentence and label are related or not.Using the crawled news headlines dataset, each headline is paired with 50% actual labels and 50% randomly selected unrelated labels. Then the model is trained using above 3 architectures with a binary cross-entropy loss with Adam optimizer.In the paper, they achieve the highest accuracy of 74% on the binary classification task with Architecture 3, followed by 72.6% on architecture 2 and 72% on architecture 1 on the separated test set of the news headlines dataset.Now, taking the trained model that can compute relatedness score of sentences with labels, the authors tested its generalization capability to unseen datasets and labels.The authors tested this process on the entire dataset and achieved 61.73%, 63% and 64.21% accuracy. In comparison, the supervised methods achieve 94.75% accuracy. The result is still interesting because without even training on a single sample, it achieves better than random accuracy.The paper proposes some really simple but clever techniques to learn the relationship between sentences and labels and achieves better than random accuracy on unseen datasets and labels. Since this was proposed in the pre-transformer era, it can be interesting to try these ideas with recent models.The recent release of GPT-3 got me interested in the state of zero-shot learning and few-shot learning in NLP. While most of the zero-shot learning research is concentrated in Computer Vision, there has been some interesting work in the NLP domain as well.I will be writing a series of blog posts to cover existing research on zero-shot learning in NLP. In this first post, I will explain the paper  by Pushp et al. This paper from December 2017 was the first work to propose a zero-shot learning paradigm for text classification.Zero-Shot Learning is the ability to detect classes that the model has never seen during training. It resembles our ability as humans to generalize and identify new things without explicit supervision.For example, let’s say we want to do  and  classification. Normally, we will train/fine-tune a new model for each dataset. In contrast, with zero-shot learning, you can perform tasks such as sentiment and news classification directly without any task-specific training.
In the paper, the authors propose a simple idea for zero-shot classification. Instead of classifying texts into X classes, they re-formulate the task as a binary classification to determine if a text and a class are related or not. 
Let’s understand their formulation and end-to-end process in more detail now.The authors crawled 4.2 million  from the web and used the  for the news article as the . After crawling, they got total  as the labels. We can see how troublesome it would have been if we had to train a supervised model on .

Each  was truncated to 28 words and anything shorter was padded.The paper uses word2vec pre-trained on Google News as the word embeddings for both the sentences as well as the labels.The paper proposes three different architecture to learn the relation between sentence and label embeddings.In this architecture, we take the mean of word embeddings in the sentence as the sentence embedding and concatenate it with the . This vector is then passed through a  to classify if the sentence and label are related or not.In this architecture, instead of taking the mean, the word embeddings are passed through an LSTM and the  of the network is treated as the sentence vector. It is concatenated with the  and then passed through a  to classify if the sentence and label are related or not.In this architecture, the embedding of each word in the sentence is concatenated with the . This combined embedding is passed through an LSTM and the  of the network is taken. It is then passed through a  to classify if the sentence and label are related or not.Using the crawled news headlines dataset, each headline is paired with 50% actual labels and 50% randomly selected unrelated labels. Then the model is trained using above 3 architectures with a binary cross-entropy loss with Adam optimizer.In the paper, they achieve the highest accuracy of 74% on the binary classification task with Architecture 3, followed by 72.6% on architecture 2 and 72% on architecture 1 on the separated test set of the news headlines dataset.Now, taking the trained model that can compute relatedness score of sentences with labels, the authors tested its generalization capability to unseen datasets and labels.The authors tested this process on the entire dataset and achieved 61.73%, 63% and 64.21% accuracy. In comparison, the supervised methods achieve 94.75% accuracy. The result is still interesting because without even training on a single sample, it achieves better than random accuracy.The paper proposes some really simple but clever techniques to learn the relationship between sentences and labels and achieves better than random accuracy on unseen datasets and labels. Since this was proposed in the pre-transformer era, it can be interesting to try these ideas with recent models.The recent release of GPT-3 got me interested in the state of zero-shot learning and few-shot learning in NLP. While most of the zero-shot learning research is concentrated in Computer Vision, there has been some interesting work in the NLP domain as well.I will be writing a series of blog posts to cover existing research on zero-shot learning in NLP. In this first post, I will explain the paper  by Pushp et al. This paper from December 2017 was the first work to propose a zero-shot learning paradigm for text classification.Zero-Shot Learning is the ability to detect classes that the model has never seen during training. It resembles our ability as humans to generalize and identify new things without explicit supervision.For example, let’s say we want to do  and  classification. Normally, we will train/fine-tune a new model for each dataset. In contrast, with zero-shot learning, you can perform tasks such as sentiment and news classification directly without any task-specific training.
In the paper, the authors propose a simple idea for zero-shot classification. Instead of classifying texts into X classes, they re-formulate the task as a binary classification to determine if a text and a class are related or not. 
Let’s understand their formulation and end-to-end process in more detail now.The authors crawled 4.2 million  from the web and used the  for the news article as the . After crawling, they got total  as the labels. We can see how troublesome it would have been if we had to train a supervised model on .

Each  was truncated to 28 words and anything shorter was padded.The paper uses word2vec pre-trained on Google News as the word embeddings for both the sentences as well as the labels.The paper proposes three different architecture to learn the relation between sentence and label embeddings.In this architecture, we take the mean of word embeddings in the sentence as the sentence embedding and concatenate it with the . This vector is then passed through a  to classify if the sentence and label are related or not.In this architecture, instead of taking the mean, the word embeddings are passed through an LSTM and the  of the network is treated as the sentence vector. It is concatenated with the  and then passed through a  to classify if the sentence and label are related or not.In this architecture, the embedding of each word in the sentence is concatenated with the . This combined embedding is passed through an LSTM and the  of the network is taken. It is then passed through a  to classify if the sentence and label are related or not.Using the crawled news headlines dataset, each headline is paired with 50% actual labels and 50% randomly selected unrelated labels. Then the model is trained using above 3 architectures with a binary cross-entropy loss with Adam optimizer.In the paper, they achieve the highest accuracy of 74% on the binary classification task with Architecture 3, followed by 72.6% on architecture 2 and 72% on architecture 1 on the separated test set of the news headlines dataset.Now, taking the trained model that can compute relatedness score of sentences with labels, the authors tested its generalization capability to unseen datasets and labels.The authors tested this process on the entire dataset and achieved 61.73%, 63% and 64.21% accuracy. In comparison, the supervised methods achieve 94.75% accuracy. The result is still interesting because without even training on a single sample, it achieves better than random accuracy.The paper proposes some really simple but clever techniques to learn the relationship between sentences and labels and achieves better than random accuracy on unseen datasets and labels. Since this was proposed in the pre-transformer era, it can be interesting to try these ideas with recent models.